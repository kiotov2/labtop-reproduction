{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEs9bJGdk_xp"
      },
      "source": [
        "# LabTOP Training on Google Colab TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrQDZKbUk_xt"
      },
      "source": [
        "## Step 1: Mount Google Drive & Setup Directories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uJCfJz9k_xu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/mimiciv/icu\n",
        "!mkdir -p /content/drive/MyDrive/mimiciv/hosp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjHA98NMk_xv"
      },
      "source": [
        "## Step 2: Download MIMIC-IV Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use existing MIMIC-IV data stored in Drive\n",
        "mimic_icu = \"/content/drive/MyDrive/mimiciv/icu\"\n",
        "mimic_hosp = \"/content/drive/MyDrive/mimiciv/hosp\"\n",
        "\n",
        "print(\"Using existing MIMIC-IV data from Drive:\")\n",
        "!ls -lh $mimic_icu\n",
        "!ls -lh $mimic_hosp\n"
      ],
      "metadata": {
        "id": "Jl7h24Tep6ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EQbCrh4k_xv",
        "outputId": "ec973596-d242-49d1-d248-7c51f938217c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✔ Completed: inputevents.csv.gz\n",
            "\n",
            "Downloading procedureevents.csv.gz ...\n",
            "   ✔ Completed: procedureevents.csv.gz\n",
            "\n",
            "Downloading outputevents.csv.gz ...\n",
            "   ✔ Completed: outputevents.csv.gz\n",
            "\n",
            "Downloading d_items.csv.gz ...\n",
            "   ✔ Completed: d_items.csv.gz\n",
            "\n",
            "=== Downloading HOSP files ===\n",
            "\n",
            "Downloading admissions.csv.gz ...\n",
            "   ✔ Completed: admissions.csv.gz\n",
            "\n",
            "Downloading patients.csv.gz ...\n",
            "   ✔ Completed: patients.csv.gz\n",
            "\n",
            "Downloading labevents.csv.gz ...\n",
            "   ✔ Completed: labevents.csv.gz\n",
            "\n",
            "Downloading d_labitems.csv.gz ...\n",
            "   ✔ Completed: d_labitems.csv.gz\n",
            "\n",
            "Downloading microbiologyevents.csv.gz ...\n",
            "   ✔ Completed: microbiologyevents.csv.gz\n",
            "\n",
            "Downloading emar.csv.gz ...\n",
            "   ✔ Completed: emar.csv.gz\n",
            "\n",
            "Downloading emar_detail.csv.gz ...\n",
            "   ✔ Completed: emar_detail.csv.gz\n",
            "\n",
            "All downloads completed successfully!\n",
            "\n",
            "Copying results to Google Drive... (this may take 1–3 minutes)\n",
            "\n",
            "Files copied to Google Drive at:\n",
            "   /content/drive/MyDrive/mimiciv/icu\n",
            "   /content/drive/MyDrive/mimiciv/hosp\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Logging into PhysioNet\")\n",
        "user = \"removed for security\"\n",
        "password = \"removed for security\"\n",
        "\n",
        "netrc_path = \"/root/.netrc\"\n",
        "with open(netrc_path, \"w\") as f:\n",
        "    f.write(f\"machine physionet.org login {user} password {password}\\n\")\n",
        "    f.write(f\"machine content.physionet.org login {user} password {password}\\n\")\n",
        "os.chmod(netrc_path, 0o600)\n",
        "print(\"Authentication configured.\")\n",
        "\n",
        "icu_files = {\n",
        "    \"icustays.csv.gz\":       \"https://physionet.org/files/mimiciv/2.2/icu/icustays.csv.gz\",\n",
        "    \"inputevents.csv.gz\":    \"https://physionet.org/files/mimiciv/2.2/icu/inputevents.csv.gz\",\n",
        "    \"procedureevents.csv.gz\":\"https://physionet.org/files/mimiciv/2.2/icu/procedureevents.csv.gz\",\n",
        "    \"outputevents.csv.gz\":   \"https://physionet.org/files/mimiciv/2.2/icu/outputevents.csv.gz\",\n",
        "    \"d_items.csv.gz\":        \"https://physionet.org/files/mimiciv/2.2/icu/d_items.csv.gz\",\n",
        "}\n",
        "\n",
        "hosp_files = {\n",
        "    \"admissions.csv.gz\":     \"https://physionet.org/files/mimiciv/2.2/hosp/admissions.csv.gz\",\n",
        "    \"patients.csv.gz\":       \"https://physionet.org/files/mimiciv/2.2/hosp/patients.csv.gz\",\n",
        "    \"labevents.csv.gz\":      \"https://physionet.org/files/mimiciv/2.2/hosp/labevents.csv.gz\",\n",
        "    \"d_labitems.csv.gz\":     \"https://physionet.org/files/mimiciv/2.2/hosp/d_labitems.csv.gz\",\n",
        "    \"microbiologyevents.csv.gz\":\"https://physionet.org/files/mimiciv/2.2/hosp/microbiologyevents.csv.gz\",\n",
        "    \"emar.csv.gz\":              \"https://physionet.org/files/mimiciv/2.2/hosp/emar.csv.gz\",\n",
        "    \"emar_detail.csv.gz\":       \"https://physionet.org/files/mimiciv/2.2/hosp/emar_detail.csv.gz\",\n",
        "}\n",
        "\n",
        "local_icu = \"/content/mimiciv/icu\"\n",
        "local_hosp = \"/content/mimiciv/hosp\"\n",
        "os.makedirs(local_icu, exist_ok=True)\n",
        "os.makedirs(local_hosp, exist_ok=True)\n",
        "print(\"Local download folders prepared.\")\n",
        "\n",
        "def download_files(file_dict, out_dir):\n",
        "    for name, url in file_dict.items():\n",
        "        print(f\"\\nDownloading {name} ...\")\n",
        "        cmd = f\"wget --progress=bar:force -c -O {out_dir}/{name} {url}\"\n",
        "        os.system(cmd)\n",
        "        print(f\"   ✔ Completed: {name}\")\n",
        "\n",
        "print(\"\\n=== Downloading ICU files ===\")\n",
        "download_files(icu_files, local_icu)\n",
        "\n",
        "print(\"\\n=== Downloading HOSP files ===\")\n",
        "download_files(hosp_files, local_hosp)\n",
        "\n",
        "print(\"\\nAll downloads completed successfully!\")\n",
        "\n",
        "drive_root = \"/content/drive/MyDrive/mimiciv\"\n",
        "drive_icu  = f\"{drive_root}/icu\"\n",
        "drive_hosp = f\"{drive_root}/hosp\"\n",
        "os.makedirs(drive_icu, exist_ok=True)\n",
        "os.makedirs(drive_hosp, exist_ok=True)\n",
        "\n",
        "print(\"\\nCopying results to Google Drive... (this may take 1–3 minutes)\")\n",
        "shutil.copytree(local_icu, drive_icu, dirs_exist_ok=True)\n",
        "shutil.copytree(local_hosp, drive_hosp, dirs_exist_ok=True)\n",
        "\n",
        "print(\"\\nFiles copied to Google Drive at:\")\n",
        "print(\"   /content/drive/MyDrive/mimiciv/icu\")\n",
        "print(\"   /content/drive/MyDrive/mimiciv/hosp\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/mimiciv/hosp/labevents.csv.gz"
      ],
      "metadata": {
        "id": "LtlL1KVjvHD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check to confirm presence of downloaded files"
      ],
      "metadata": {
        "id": "l4JTiU3FkBwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "required_files = [\n",
        "    \"icu/icustays.csv.gz\",\n",
        "    \"icu/inputevents.csv.gz\",\n",
        "    \"icu/procedureevents.csv.gz\",\n",
        "    \"icu/outputevents.csv.gz\",\n",
        "    \"icu/d_items.csv.gz\",\n",
        "    \"hosp/admissions.csv.gz\",\n",
        "    \"hosp/patients.csv.gz\",\n",
        "    \"hosp/labevents.csv.gz\",\n",
        "    \"hosp/d_labitems.csv.gz\",\n",
        "]\n",
        "\n",
        "base = \"/content/drive/MyDrive/mimiciv\"\n",
        "\n",
        "for file in required_files:\n",
        "    path = f\"{base}/{file}\"\n",
        "    if os.path.exists(path):\n",
        "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
        "        status = \"GOOD\" if size_mb > 0.01 else \"EMPTY\"\n",
        "        print(f\"{status} {file}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"MISSING: {file}\")"
      ],
      "metadata": {
        "id": "hucg2PcmkAT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/MyDrive/mimiciv/icu/inputevents.csv.gz\"\n",
        "if os.path.exists(path):\n",
        "    size_mb = os.path.getsize(path) / (1024*1024)\n",
        "    print(f\"Current size: {size_mb:.1f} MB / ~2500 MB\")"
      ],
      "metadata": {
        "id": "46UJO8Z_pHPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I18HYItTk_xx"
      },
      "source": [
        "## Step 3: Install PyTorch XLA for TPU Support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnCeGRfQk_xx"
      },
      "outputs": [],
      "source": [
        "!pip install torch torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html\n",
        "\n",
        "!pip install accelerate transformers hydra-core omegaconf pandas numpy scipy scikit-learn tqdm datasets tokenizers safetensors huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB83vJfMk_xy"
      },
      "source": [
        "## Step 4: Verify TPU is Available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foAO88Ebk_xy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.runtime as xr\n",
        "\n",
        "device = xm.xla_device()\n",
        "print(f\"TPU Device: {device}\")\n",
        "\n",
        "# Use the new API to get world size\n",
        "try:\n",
        "    print(f\"Number of TPU cores: {xr.world_size()}\")\n",
        "except:\n",
        "    print(f\"Number of devices: {xr.global_runtime_device_count()}\")\n",
        "\n",
        "# Test tensor on TPU\n",
        "test_tensor = torch.randn(3, 3).to(device)\n",
        "print(f\"Test tensor created on device: {test_tensor.device}\")\n",
        "print(\"XLA device is ready!\")\n",
        "\n",
        "# Check if it's actually TPU\n",
        "import os\n",
        "print(f\"\\nPJRT_DEVICE: {os.environ.get('PJRT_DEVICE', 'Not set')}\")\n",
        "if 'CPU' in str(device) or os.environ.get('PJRT_DEVICE') == 'CPU':\n",
        "    print(\"WARNING: Running on CPU, not TPU!\")\n",
        "    print(\"   Make sure Runtime → Change runtime type → TPU v2\")\n",
        "else:\n",
        "    print(\"TPU is active!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Clone Repository"
      ],
      "metadata": {
        "id": "4UU5lREqxdkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf labtop-reproduction\n",
        "!git clone https://github.com/kiotov2/labtop-reproduction.git\n",
        "%cd labtop-reproduction"
      ],
      "metadata": {
        "id": "i3d4e7D7qcG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Baq91Y47k_xy"
      },
      "source": [
        "## Step 6: Slice MIMIC-IV Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DV8VDFrk_xy"
      },
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction\n",
        "\n",
        "!python scripts/slice_mimic.py \\\n",
        "    --source /content/drive/MyDrive/mimiciv \\\n",
        "    --dest ./data_small \\\n",
        "    --n_stays 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPdeFkiYk_xy"
      },
      "source": [
        "## Step 7: Create TPU-Optimized Configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7qq0reBk_xz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"src/config/data\", exist_ok=True)\n",
        "os.makedirs(\"src/config/train\", exist_ok=True)\n",
        "\n",
        "# Data config\n",
        "with open(\"src/config/data/mimiciv_small.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"defaults:\n",
        "  - mimiciv\n",
        "\n",
        "raw_data_path: /content/labtop-reproduction/data_small\n",
        "min_los: 1\n",
        "debug_table_sample_ratio: 1.0\n",
        "\"\"\")\n",
        "\n",
        "# Train config\n",
        "with open(\"src/config/train/train_small_tpu.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"defaults:\n",
        "  - train_base\n",
        "\n",
        "epochs: 5\n",
        "batch_size: 2              # Reduced from 8 to prevent OOM\n",
        "gradient_accumulation_steps: 8  # Increased to keep effective batch size = 16\n",
        "use_wandb: false\n",
        "patience: 1\n",
        "max_seq_len: 512\n",
        "lr: 1e-4\n",
        "\"\"\")\n",
        "\n",
        "print(\"Configs created for TPU training (MEMORY-OPTIMIZED)\")\n",
        "print(\"   - Batch size: 2 per core (reduced for memory)\")\n",
        "print(\"   - Gradient accumulation: 8 steps\")\n",
        "print(\"   - Effective batch size: 16 (2 × 8)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decompress all the sliced data files\n",
        "!cd /content/labtop-reproduction/data_small/icu && for f in *.csv.gz; do gunzip -k \"$f\"; done\n",
        "!cd /content/labtop-reproduction/data_small/hosp && for f in *.csv.gz; do gunzip -k \"$f\"; done\n",
        "\n",
        "print(\"Files decompressed!\")\n",
        "\n",
        "# Verify\n",
        "!ls -lh /content/labtop-reproduction/data_small/icu/icustays.csv\n",
        "!ls -lh /content/labtop-reproduction/data_small/hosp/"
      ],
      "metadata": {
        "id": "e2SmcVcHD_NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Setup authentication\n",
        "netrc_path = \"/root/.netrc\"\n",
        "with open(netrc_path, \"w\") as f:\n",
        "    f.write(f\"machine physionet.org login kiotov2 password <password>\\n\")\n",
        "    f.write(f\"machine content.physionet.org login kiotov2 password <password>\\n\")\n",
        "os.chmod(netrc_path, 0o600)\n",
        "\n",
        "!wget -O /content/labtop-reproduction/data_small/icu/d_items.csv.gz https://physionet.org/files/mimiciv/2.2/icu/d_items.csv.gz\n",
        "\n",
        "# Decompress it\n",
        "!gunzip -k /content/labtop-reproduction/data_small/icu/d_items.csv.gz\n",
        "\n",
        "# Verify\n",
        "!ls -lh /content/labtop-reproduction/data_small/icu/d_items.csv\n",
        "\n",
        "print(\"d_items downloaded and decompressed!\")"
      ],
      "metadata": {
        "id": "aDSuU03wEQC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQt7Cvxlk_xz"
      },
      "source": [
        "## Step 8: Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decompress d_items specifically\n",
        "!gunzip -k /content/labtop-reproduction/data_small/icu/d_items.csv.gz\n",
        "\n",
        "# Verify it's there\n",
        "!ls -lh /content/labtop-reproduction/data_small/icu/d_items.csv\n",
        "\n",
        "print(\"d_items.csv decompressed!\")"
      ],
      "metadata": {
        "id": "5vbc465o2dEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgWpNUb-k_xz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction/labtop\n",
        "\n",
        "!python src/scripts/preprocess.py \\\n",
        "    data=mimiciv_small \\\n",
        "    data_path=/content/labtop-reproduction/data_small \\\n",
        "    data.use_tables=\"[labevents,inputevents,procedureevents,outputevents]\" \\\n",
        "    max_seq_len=512\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined check\n",
        "import os\n",
        "\n",
        "print(\"DATA STATUS CHECK\\n\" + \"=\"*50)\n",
        "\n",
        "# Check 1: Sliced data\n",
        "sliced_exists = os.path.exists(\"/content/labtop-reproduction/data_small/icu\") and \\\n",
        "                os.path.exists(\"/content/labtop-reproduction/data_small/hosp\")\n",
        "print(f\"{'GOOD' if sliced_exists else 'BAD'} Sliced data (data_small/)\")\n",
        "\n",
        "# Check 2: Preprocessed data\n",
        "preprocessed_exists = os.path.exists(\"/content/labtop-reproduction/data/mimiciv\")\n",
        "if preprocessed_exists:\n",
        "    subdirs = os.listdir(\"/content/labtop-reproduction/data/mimiciv\")\n",
        "    has_datasets = any('dataset' in str(os.listdir(f\"/content/labtop-reproduction/data/mimiciv/{d}\"))\n",
        "                      for d in subdirs if os.path.isdir(f\"/content/labtop-reproduction/data/mimiciv/{d}\"))\n",
        "    preprocessed_exists = has_datasets\n",
        "\n",
        "print(f\"{'GOOD' if preprocessed_exists else 'BAD'} Preprocessed data (data/mimiciv/)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VERDICT:\")\n",
        "if not sliced_exists:\n",
        "    print(\"Need to run: SLICING\")\n",
        "if not preprocessed_exists:\n",
        "    print(\"Need to run: PREPROCESSING\")\n",
        "if sliced_exists and preprocessed_exists:\n",
        "    print(\"ALL DATA READY - Skip to training!\")"
      ],
      "metadata": {
        "id": "534mdyft6SLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what's actually in the file\n",
        "!cat src/config/train/train_small_tpu.yaml"
      ],
      "metadata": {
        "id": "OKmV3EsXF5g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch trainer.py to disable accelerate.save_state on TPU\n",
        "trainer_path = \"/content/labtop-reproduction/labtop/src/core/models/trainer.py\"\n",
        "\n",
        "with open(trainer_path, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Replace the save_state call with a TPU safe version\n",
        "patched = code.replace(\n",
        "    \"self.accelerator.save_state(self.model_dir)\",\n",
        "    \"print('Skipping save_state on TPU (patched).')\"\n",
        ")\n",
        "\n",
        "with open(trainer_path, \"w\") as f:\n",
        "    f.write(patched)\n",
        "\n",
        "print(\"Patched trainer.py to skip save_state on TPU\")\n"
      ],
      "metadata": {
        "id": "XbCs8A5WKnPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP4Mf9Hkk_xz"
      },
      "source": [
        "## Step 9: Train on TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI3kKmVAk_xz"
      },
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction/labtop\n",
        "\n",
        "# Clear Hydra cache\n",
        "!rm -rf .hydra\n",
        "!rm -rf outputs\n",
        "\n",
        "\n",
        "print(\"Cache cleared!\")\n",
        "\n",
        "# Now run with explicit override\n",
        "import os\n",
        "data_folder = os.listdir(\"/content/labtop-reproduction/data/mimiciv\")[0]\n",
        "\n",
        "!python src/scripts/train.py \\\n",
        "    data=mimiciv_small \\\n",
        "    train=train_small_tpu \\\n",
        "    max_seq_len=512 \\\n",
        "    train.epochs=5 \\\n",
        "    data_path=/content/labtop-reproduction/data/mimiciv/{data_folder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQjeU2tk_x0"
      },
      "source": [
        "## Step 10: Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVhdTwDLk_x0"
      },
      "outputs": [],
      "source": [
        "ls -R ./trained_models/mimiciv_labevents_inputevents_procedureevents_outputevents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XPKOJmJk_x0"
      },
      "source": [
        "## Monitor TPU Utilization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDcYWABzk_x0"
      },
      "outputs": [],
      "source": [
        "import torch_xla.debug.metrics as met\n",
        "\n",
        "# Print TPU metrics\n",
        "print(met.metrics_report())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "machine_shape": "hm"
    },
    "accelerator": "TPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
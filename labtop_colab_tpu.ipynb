{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LabTOP Training on Google Colab TPU\n",
        "\n",
        "**IMPORTANT: Before running, change Runtime ‚Üí Change runtime type ‚Üí TPU v2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Mount Google Drive & Setup Directories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/mimiciv/icu\n",
        "!mkdir -p /content/drive/MyDrive/mimiciv/hosp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Download MIMIC-IV Data (Skip if already downloaded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Logging into PhysioNet\")\n",
        "user = \"kiotov2\"\n",
        "password = \"nWnpPiP8&QqsXnf\"\n",
        "\n",
        "# Create ~/.netrc for wget authentication\n",
        "netrc_path = \"/root/.netrc\"\n",
        "with open(netrc_path, \"w\") as f:\n",
        "    f.write(f\"machine physionet.org login {user} password {password}\\n\")\n",
        "    f.write(f\"machine content.physionet.org login {user} password {password}\\n\")\n",
        "os.chmod(netrc_path, 0o600)\n",
        "print(\"‚úÖ Authentication configured.\")\n",
        "\n",
        "# Define all files to download\n",
        "icu_files = {\n",
        "    \"icustays.csv.gz\":       \"https://physionet.org/files/mimiciv/2.2/icu/icustays.csv.gz\",\n",
        "    \"inputevents.csv.gz\":    \"https://physionet.org/files/mimiciv/2.2/icu/inputevents.csv.gz\",\n",
        "    \"procedureevents.csv.gz\":\"https://physionet.org/files/mimiciv/2.2/icu/procedureevents.csv.gz\",\n",
        "    \"outputevents.csv.gz\":   \"https://physionet.org/files/mimiciv/2.2/icu/outputevents.csv.gz\",\n",
        "    \"d_items.csv.gz\":        \"https://physionet.org/files/mimiciv/2.2/icu/d_items.csv.gz\",\n",
        "}\n",
        "\n",
        "hosp_files = {\n",
        "    \"admissions.csv.gz\":     \"https://physionet.org/files/mimiciv/2.2/hosp/admissions.csv.gz\",\n",
        "    \"patients.csv.gz\":       \"https://physionet.org/files/mimiciv/2.2/hosp/patients.csv.gz\",\n",
        "    \"labevents.csv.gz\":      \"https://physionet.org/files/mimiciv/2.2/hosp/labevents.csv.gz\",\n",
        "    \"d_labitems.csv.gz\":     \"https://physionet.org/files/mimiciv/2.2/hosp/d_labitems.csv.gz\",\n",
        "}\n",
        "\n",
        "# Local download dirs (fast)\n",
        "local_icu = \"/content/mimiciv/icu\"\n",
        "local_hosp = \"/content/mimiciv/hosp\"\n",
        "os.makedirs(local_icu, exist_ok=True)\n",
        "os.makedirs(local_hosp, exist_ok=True)\n",
        "print(\"üìÅ Local download folders prepared.\")\n",
        "\n",
        "# Download helper\n",
        "def download_files(file_dict, out_dir):\n",
        "    for name, url in file_dict.items():\n",
        "        print(f\"\\n‚¨áÔ∏è Downloading {name} ...\")\n",
        "        cmd = f\"wget --progress=bar:force -c -O {out_dir}/{name} {url}\"\n",
        "        os.system(cmd)\n",
        "        print(f\"   ‚úî Completed: {name}\")\n",
        "\n",
        "print(\"\\n=== üè• Downloading ICU files ===\")\n",
        "download_files(icu_files, local_icu)\n",
        "\n",
        "print(\"\\n=== üß¨ Downloading HOSP files ===\")\n",
        "download_files(hosp_files, local_hosp)\n",
        "\n",
        "print(\"\\nüéâ All downloads completed successfully!\")\n",
        "\n",
        "# Move to Google Drive\n",
        "drive_root = \"/content/drive/MyDrive/mimiciv\"\n",
        "drive_icu  = f\"{drive_root}/icu\"\n",
        "drive_hosp = f\"{drive_root}/hosp\"\n",
        "os.makedirs(drive_icu, exist_ok=True)\n",
        "os.makedirs(drive_hosp, exist_ok=True)\n",
        "\n",
        "print(\"\\nüì¶ Copying results to Google Drive... (this may take 1‚Äì3 minutes)\")\n",
        "shutil.copytree(local_icu, drive_icu, dirs_exist_ok=True)\n",
        "shutil.copytree(local_hosp, drive_hosp, dirs_exist_ok=True)\n",
        "\n",
        "print(\"\\n‚úÖ Files copied to Google Drive at:\")\n",
        "print(\"   /content/drive/MyDrive/mimiciv/icu\")\n",
        "print(\"   /content/drive/MyDrive/mimiciv/hosp\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Clone Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!rm -rf labtop-reproduction\n",
        "!git clone https://github.com/kiotov2/labtop-reproduction.git\n",
        "%cd labtop-reproduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Install PyTorch XLA for TPU Support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch XLA for TPU support\n",
        "!pip install torch~=2.5.0 torch_xla[tpu]~=2.5.0 -f https://storage.googleapis.com/libtpu-releases/index.html\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install accelerate transformers hydra-core omegaconf pandas numpy scipy scikit-learn tqdm datasets tokenizers safetensors huggingface-hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify TPU is Available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Check TPU availability\n",
        "device = xm.xla_device()\n",
        "print(f\"TPU Device: {device}\")\n",
        "print(f\"Number of TPU cores: {xm.xrt_world_size()}\")\n",
        "\n",
        "# Test tensor on TPU\n",
        "test_tensor = torch.randn(3, 3).to(device)\n",
        "print(f\"Test tensor created on TPU: {test_tensor.device}\")\n",
        "print(\"‚úÖ TPU is ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Slice MIMIC-IV Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction\n",
        "\n",
        "!python scripts/slice_mimic.py \\\n",
        "    --source /content/drive/MyDrive/mimiciv \\\n",
        "    --dest ./data_small \\\n",
        "    --n_stays 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create TPU-Optimized Configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"labtop/src/config/data\", exist_ok=True)\n",
        "os.makedirs(\"labtop/src/config/train\", exist_ok=True)\n",
        "\n",
        "# Data config\n",
        "with open(\"labtop/src/config/data/mimiciv_small.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"defaults:\n",
        "  - mimiciv\n",
        "\n",
        "raw_data_path: /content/labtop-reproduction/data_small\n",
        "min_los: 1\n",
        "debug_table_sample_ratio: 1.0\n",
        "\"\"\")\n",
        "\n",
        "# Train config - TPU optimized\n",
        "# TPUs work best with batch sizes divisible by 8 (per core)\n",
        "# With 8 TPU cores, effective batch size = batch_size * gradient_accumulation_steps * 8\n",
        "with open(\"labtop/src/config/train/train_small_tpu.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"defaults:\n",
        "  - train_base\n",
        "\n",
        "epochs: 2\n",
        "batch_size: 8        # Per-core batch size (8 cores * 8 = 64 total)\n",
        "gradient_accumulation_steps: 4  # Effective batch size = 256\n",
        "use_wandb: false\n",
        "patience: 1\n",
        "max_seq_len: 512\n",
        "lr: 1e-4\n",
        "\"\"\")\n",
        "\n",
        "print(\"‚úÖ Configs created for TPU training\")\n",
        "print(\"   - Batch size: 8 per core\")\n",
        "print(\"   - Gradient accumulation: 4 steps\")\n",
        "print(\"   - Effective batch size: ~256 (with 8 TPU cores)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction/labtop\n",
        "\n",
        "!python src/scripts/preprocess.py \\\n",
        "    data=mimiciv_small \\\n",
        "    max_seq_len=512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Train on TPU üöÄ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction/labtop\n",
        "\n",
        "# Train with TPU - Accelerate will automatically detect and use TPU\n",
        "!python src/scripts/train.py \\\n",
        "    data=mimiciv_small \\\n",
        "    train=train_small_tpu \\\n",
        "    max_seq_len=512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/labtop-reproduction/labtop\n",
        "\n",
        "!python src/scripts/evaluate.py \\\n",
        "    data=mimiciv_small \\\n",
        "    train=train_small_tpu \\\n",
        "    max_seq_len=512\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor TPU Utilization (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch_xla.debug.metrics as met\n",
        "\n",
        "# Print TPU metrics\n",
        "print(met.metrics_report())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
